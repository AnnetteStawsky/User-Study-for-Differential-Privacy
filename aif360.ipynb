{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "# from aif360.metrics import DatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n"
     ]
    }
   ],
   "source": [
    "#Specify sensitive attribute\n",
    "dataset_orig_panel19_train = GermanDataset()\n",
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "print(sens_attr)\n",
    "unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.8965673282047968\n"
     ]
    }
   ],
   "source": [
    "#TODO 1\n",
    "dataset_orig_panel19_train, dataset_orig_panel19_test = GermanDataset().split([0.7], shuffle=True)\n",
    "metric_orig_panel19 = BinaryLabelDatasetMetric(\n",
    "        GermanDataset(),\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_orig_panel19 = MetricTextExplainer(metric_orig_panel19)\n",
    "\n",
    "print(explainer_orig_panel19.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2 train random forest classifier\n",
    "dataset = dataset_orig_panel19_train\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      RandomForestClassifier(n_estimators=500, min_samples_leaf=25))\n",
    "fit_params = {'randomforestclassifier__sample_weight': dataset.instance_weights}\n",
    "rf_orig_panel19 = model.fit(dataset.features, dataset.labels.ravel(), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dataset_test = dataset_orig_panel19_test\n",
    "predictions= model.predict(dataset_test.features)\n",
    "prediction_dataset=copy.deepcopy(dataset_test)\n",
    "#prediction_dataset = copy.deepcopy(dataset)\n",
    "prediction_dataset.labels = predictions\n",
    "#bldataset = BinaryLabelDataset(dataset, privileged_groups[0].get('sex'), unprivileged_groups[0].get('sex'))\n",
    "metric_class = ClassificationMetric(dataset_test, prediction_dataset, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966297544535389\n",
      "-0.003279320987654266\n"
     ]
    }
   ],
   "source": [
    "print(metric_class.disparate_impact())\n",
    "print(metric_class.equal_opportunity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bias Mitigation TODO 3\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_panel19_train = RW.fit_transform(dataset_orig_panel19_train)\n",
    "dataset_transf_panel19_test = RW.fit_transform(dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 1.0\n"
     ]
    }
   ],
   "source": [
    "metric_transf = BinaryLabelDatasetMetric(\n",
    "        dataset_transf_panel19_train,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        privileged_groups=privileged_groups)\n",
    "explainer_transf = MetricTextExplainer(metric_transf)\n",
    "\n",
    "print(explainer_transf.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using random tree on transformed data\n",
    "dataset1 = dataset_transf_panel19_train\n",
    "model1 = make_pipeline(StandardScaler(),\n",
    "                      RandomForestClassifier(n_estimators=500, min_samples_leaf=25))\n",
    "fit_params = {'randomforestclassifier__sample_weight': dataset1.instance_weights}\n",
    "rf_transf_panel19 = model1.fit(dataset1.features, dataset1.labels.ravel(), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_test = dataset_transf_panel19_test\n",
    "predictions1= model1.predict(dataset1_test.features)\n",
    "prediction_dataset1=copy.deepcopy(dataset1_test)\n",
    "prediction_dataset1.labels = predictions\n",
    "metric_class1 = ClassificationMetric(dataset1_test, prediction_dataset1, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0025227872689229\n",
      "-0.003279320987654044\n"
     ]
    }
   ],
   "source": [
    "print(metric_class1.disparate_impact())\n",
    "print(metric_class1.equal_opportunity_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
